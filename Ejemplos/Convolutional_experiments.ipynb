{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo tomado de https://github.com/StrikingLoo/Cats-and-dogs-classifier-tensorflow-CNN/blob/master/Convolutional_experiments.ipynb. El ejemplo ha sido simplificado y adaptado para el curso introduccion de aprendizaje de maquinas de la Maestria en Ingenieria de la Universidad del Magdalena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path_cat = './PetImages\\\\Cat/*'\n",
    "dir_path_dog = './PetImages\\\\Dog/*'\n",
    "IMG_SIZE = (94, 125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixels_from_path(file_path):\n",
    "    im = Image.open(file_path)\n",
    "    im = im.resize(IMG_SIZE)\n",
    "    np_im = np.array(im)\n",
    "    \n",
    "    return np_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12501\n",
      "12501\n"
     ]
    }
   ],
   "source": [
    "cat_file_list = glob.glob(dir_path_cat) #Busca en el directorio dado todas las imagenes que alli se encuentran\n",
    "dog_file_list = glob.glob(dir_path_dog)\n",
    "print(len(cat_file_list))\n",
    "print(len(dog_file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_size = [IMG_SIZE[1], IMG_SIZE[0], 3] \n",
    "\n",
    "def create_set(file_list, nItems):\n",
    "    new_set = []\n",
    "    for im in file_list[:nItems]:\n",
    "       new_item = pixels_from_path(im)\n",
    "       if len(new_item.shape) != 3:\n",
    "            print('Imagen con tamano diferente', im)\n",
    "       else:\n",
    "          new_set.append(new_item)\n",
    "    \n",
    "    return new_set   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading training cat images...\n",
      "Imagen con tamano diferente ./PetImages\\Cat\\10125.jpg\n",
      "Imagen con tamano diferente ./PetImages\\Cat\\10501.jpg\n",
      "Imagen con tamano diferente ./PetImages\\Cat\\10820.jpg\n",
      "Imagen con tamano diferente ./PetImages\\Cat\\11095.jpg\n",
      "Imagen con tamano diferente ./PetImages\\Cat\\11210.jpg\n",
      "Imagen con tamano diferente ./PetImages\\Cat\\11565.jpg\n",
      "loading training dog images...\n",
      "Imagen con tamano diferente ./PetImages\\Dog\\10158.jpg\n",
      "Imagen con tamano diferente ./PetImages\\Dog\\10401.jpg\n",
      "Imagen con tamano diferente ./PetImages\\Dog\\10747.jpg\n",
      "Imagen con tamano diferente ./PetImages\\Dog\\10797.jpg\n",
      "Imagen con tamano diferente ./PetImages\\Dog\\11410.jpg\n",
      "Imagen con tamano diferente ./PetImages\\Dog\\11675.jpg\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_SIZE = 2048\n",
    "\n",
    "print(\"loading training cat images...\")\n",
    "cat_train_set = create_set( cat_file_list, SAMPLE_SIZE)\n",
    "\n",
    "print(\"loading training dog images...\")\n",
    "dog_train_set = create_set(dog_file_list, SAMPLE_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2042\n",
      "2042\n"
     ]
    }
   ],
   "source": [
    "print(len(cat_train_set))\n",
    "print(len(dog_train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagen con tamano diferente ./PetImages\\Cat\\11874.jpg\n",
      "Imagen con tamano diferente ./PetImages\\Cat\\11935.jpg\n",
      "Imagen con tamano diferente ./PetImages\\Cat\\12080.jpg\n",
      "Imagen con tamano diferente ./PetImages\\Dog\\11849.jpg\n",
      "Imagen con tamano diferente ./PetImages\\Dog\\11853.jpg\n"
     ]
    }
   ],
   "source": [
    "TEST_SIZE = 512\n",
    "cat_file_list_test =  cat_file_list[SAMPLE_SIZE+1:]\n",
    "cat_test_set = create_set(cat_file_list_test, TEST_SIZE)\n",
    "\n",
    "dog_file_list_test =  dog_file_list[SAMPLE_SIZE+1:]\n",
    "dog_test_set = create_set(dog_file_list_test, TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "509\n",
      "510\n"
     ]
    }
   ],
   "source": [
    "print(len(cat_test_set))\n",
    "print(len(dog_test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_size(im_list):\n",
    "   valid_size = (IMG_SIZE[1], IMG_SIZE[0], 3) \n",
    "   for im in im_list:\n",
    "       im_shape = im.shape \n",
    "       #if not (np.array(im_shape) == np.array(valid_size)).all():\n",
    "       if not (np.array_equal(np.array(im_shape), np.array(valid_size))):\n",
    "          print('hay una imagen con un tamano:', im_shape)\n",
    "          im_list.remove(im)\n",
    "   return im_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hay una imagen con un tamano: (125, 94, 4)\n",
      "4083\n",
      "1019\n",
      "4083\n",
      "1019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-eca6d32de37c>:8: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  im_list.remove(im)\n"
     ]
    }
   ],
   "source": [
    "cat_train_set = validate_size(cat_train_set)\n",
    "dog_train_set = validate_size(dog_train_set)\n",
    "\n",
    "cat_test_set = validate_size(cat_test_set)\n",
    "dog_test_set = validate_size(dog_test_set)\n",
    "\n",
    "labels_cat_train = np.ones(len(cat_train_set))\n",
    "labels_dog_train = np.zeros(len(dog_train_set))\n",
    "\n",
    "labels_cat_test = np.ones(len(cat_test_set))\n",
    "labels_dog_test = np.zeros(len(dog_test_set))\n",
    "\n",
    "train_set =  cat_train_set  + dog_train_set\n",
    "y_train = np.concatenate((labels_cat_train, labels_dog_train), axis=None)\n",
    " \n",
    "test_set =  cat_test_set  + dog_test_set\n",
    "y_test = np.concatenate((labels_cat_test, labels_dog_test), axis=None)\n",
    "\n",
    "print(len(train_set))\n",
    "print(len(test_set))\n",
    "print(len(y_train))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4083, 125, 94, 3)\n",
      "(1019, 125, 94, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(train_set)\n",
    "X_test = np.array(test_set)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Un MLP normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "img_size = IMG_SIZE\n",
    "\n",
    "total_pixels = img_size[0] *img_size[1] * 3\n",
    "fc_size = 512\n",
    "\n",
    "#Definicion del modelo\n",
    "\n",
    "inputs = keras.Input(shape=(img_size[1], img_size[0],3), name='ani_image') \n",
    "x = layers.Flatten(name = 'flattened_img')(inputs) #turn image to vector.\n",
    "\n",
    "x = layers.Dense(fc_size, activation='relu', name='first_layer')(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid', name='class')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "customAdam = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=customAdam,  # Optimizer\n",
    "              # Loss function to minimize\n",
    "              loss=\"mean_squared_error\",\n",
    "              # List of metrics to monitor\n",
    "              metrics=[\"accuracy\",\"mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Fit model on training data\n",
      "Epoch 1/10\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.4999 - accuracy: 0.5001 - mean_squared_error: 0.4999 - val_loss: 0.5005 - val_accuracy: 0.4995 - val_mean_squared_error: 0.5005\n",
      "Epoch 2/10\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.4999 - accuracy: 0.5001 - mean_squared_error: 0.4999 - val_loss: 0.5005 - val_accuracy: 0.4995 - val_mean_squared_error: 0.5005\n",
      "Epoch 3/10\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.4999 - accuracy: 0.5001 - mean_squared_error: 0.4999 - val_loss: 0.5005 - val_accuracy: 0.4995 - val_mean_squared_error: 0.5005\n",
      "Epoch 4/10\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.4999 - accuracy: 0.5001 - mean_squared_error: 0.4999 - val_loss: 0.5005 - val_accuracy: 0.4995 - val_mean_squared_error: 0.5005\n",
      "Epoch 5/10\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.4999 - accuracy: 0.5001 - mean_squared_error: 0.4999 - val_loss: 0.5005 - val_accuracy: 0.4995 - val_mean_squared_error: 0.5005\n",
      "Epoch 6/10\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.4999 - accuracy: 0.5001 - mean_squared_error: 0.4999 - val_loss: 0.5005 - val_accuracy: 0.4995 - val_mean_squared_error: 0.5005\n",
      "Epoch 7/10\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.4999 - accuracy: 0.5001 - mean_squared_error: 0.4999 - val_loss: 0.5005 - val_accuracy: 0.4995 - val_mean_squared_error: 0.5005\n",
      "Epoch 8/10\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.4999 - accuracy: 0.5001 - mean_squared_error: 0.4999 - val_loss: 0.5005 - val_accuracy: 0.4995 - val_mean_squared_error: 0.5005\n",
      "Epoch 9/10\n",
      "128/128 [==============================] - 7s 56ms/step - loss: 0.4999 - accuracy: 0.5001 - mean_squared_error: 0.4999 - val_loss: 0.5005 - val_accuracy: 0.4995 - val_mean_squared_error: 0.5005\n",
      "Epoch 10/10\n",
      "128/128 [==============================] - 7s 57ms/step - loss: 0.4999 - accuracy: 0.5001 - mean_squared_error: 0.4999 - val_loss: 0.5005 - val_accuracy: 0.4995 - val_mean_squared_error: 0.5005\n"
     ]
    }
   ],
   "source": [
    "print('# Fit model on training data')\n",
    "\n",
    "history = model.fit(X_train, \n",
    "                    y_train,\n",
    "                    batch_size=32, \n",
    "                    shuffle = True, #important since we loaded cats first, dogs second.\n",
    "                    epochs=10,\n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Convolutional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_layer_size = 128\n",
    "img_size = IMG_SIZE\n",
    "\n",
    "conv_inputs = keras.Input(shape=(img_size[1], img_size[0],3), name='ani_image')\n",
    "conv_layer = layers.Conv2D(24, kernel_size=3, activation='relu')(conv_inputs)\n",
    "conv_layer = layers.MaxPool2D(pool_size=(2,2))(conv_layer)\n",
    "conv_x = layers.Flatten(name = 'flattened_features')(conv_layer) #turn image to vector.\n",
    "\n",
    "conv_x = layers.Dense(fc_layer_size, activation='relu', name='first_layer')(conv_x)\n",
    "conv_x = layers.Dense(fc_layer_size, activation='relu', name='second_layer')(conv_x)\n",
    "conv_outputs = layers.Dense(1, activation='sigmoid', name='class')(conv_x)\n",
    "\n",
    "conv_model = keras.Model(inputs=conv_inputs, outputs=conv_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "customAdam = keras.optimizers.Adam(lr=1e-6)\n",
    "conv_model.compile(optimizer=customAdam,  # Optimizer\n",
    "              # Loss function to minimize\n",
    "              loss=\"binary_crossentropy\",\n",
    "              # List of metrics to monitor\n",
    "              metrics=[\"accuracy\",\"mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Fit model on training data\n",
      "Epoch 1/5\n",
      "64/64 [==============================] - 10s 150ms/step - loss: 1.3768 - accuracy: 0.5964 - mean_squared_error: 0.3226 - val_loss: 1.6542 - val_accuracy: 0.5613 - val_mean_squared_error: 0.3545\n",
      "Epoch 2/5\n",
      "64/64 [==============================] - 9s 148ms/step - loss: 1.2982 - accuracy: 0.6106 - mean_squared_error: 0.3103 - val_loss: 1.6013 - val_accuracy: 0.5643 - val_mean_squared_error: 0.3494\n",
      "Epoch 3/5\n",
      "64/64 [==============================] - 9s 147ms/step - loss: 1.2364 - accuracy: 0.6133 - mean_squared_error: 0.3033 - val_loss: 1.5630 - val_accuracy: 0.5790 - val_mean_squared_error: 0.3446\n",
      "Epoch 4/5\n",
      "64/64 [==============================] - 9s 148ms/step - loss: 1.1872 - accuracy: 0.6199 - mean_squared_error: 0.2967 - val_loss: 1.5507 - val_accuracy: 0.5741 - val_mean_squared_error: 0.3408\n",
      "Epoch 5/5\n",
      "64/64 [==============================] - 10s 151ms/step - loss: 1.1443 - accuracy: 0.6299 - mean_squared_error: 0.2894 - val_loss: 1.5087 - val_accuracy: 0.5761 - val_mean_squared_error: 0.3365\n"
     ]
    }
   ],
   "source": [
    "print('# Fit model on training data')\n",
    "\n",
    "history = conv_model.fit(X_train, \n",
    "                    y_train, #we pass it th labels\n",
    "                    #If the model is taking forever to train, make this bigger\n",
    "                    #If it is taking forever to load for the first epoch, make this smaller\n",
    "                    batch_size=64, \n",
    "                    shuffle = True,\n",
    "                    epochs=5,\n",
    "                    # We pass it validation data to\n",
    "                    # monitor loss and metrics\n",
    "                    # at the end of each epoch\n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigger Convolutional Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_layer_size = 256\n",
    "img_size = IMG_SIZE\n",
    "\n",
    "conv_inputs = keras.Input(shape=(img_size[1], img_size[0],3), name='ani_image')\n",
    "\n",
    "conv_layer = layers.Conv2D(48, kernel_size=3, activation='relu')(conv_inputs)\n",
    "conv_layer = layers.MaxPool2D(pool_size=(2,2))(conv_layer)\n",
    "\n",
    "conv_layer = layers.Conv2D(48, kernel_size=3, activation='relu')(conv_layer)\n",
    "conv_layer = layers.MaxPool2D(pool_size=(2,2))(conv_layer)\n",
    "\n",
    "conv_x = layers.Flatten(name = 'flattened_features')(conv_layer) #turn image to vector.\n",
    "\n",
    "conv_x = layers.Dense(fc_layer_size, activation='relu', name='first_layer')(conv_x)\n",
    "conv_x = layers.Dense(fc_layer_size, activation='relu', name='second_layer')(conv_x)\n",
    "conv_outputs = layers.Dense(1, activation='sigmoid', name='class')(conv_x)\n",
    "\n",
    "conv_model = keras.Model(inputs=conv_inputs, outputs=conv_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "customAdam = keras.optimizers.Adam(lr=1e-6)\n",
    "conv_model.compile(optimizer=customAdam,  # Optimizer\n",
    "              # Loss function to minimize\n",
    "              loss=\"binary_crossentropy\",\n",
    "              # List of metrics to monitor\n",
    "              metrics=[\"accuracy\",\"mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Fit model on training data\n",
      "Epoch 1/15\n",
      "64/64 [==============================] - 24s 372ms/step - loss: 2.1681 - accuracy: 0.4989 - mean_squared_error: 0.4251 - val_loss: 1.9135 - val_accuracy: 0.5074 - val_mean_squared_error: 0.4106\n",
      "Epoch 2/15\n",
      "64/64 [==============================] - 24s 378ms/step - loss: 1.6408 - accuracy: 0.5376 - mean_squared_error: 0.3772 - val_loss: 1.6676 - val_accuracy: 0.5280 - val_mean_squared_error: 0.3841\n",
      "Epoch 3/15\n",
      "64/64 [==============================] - 24s 372ms/step - loss: 1.3970 - accuracy: 0.5569 - mean_squared_error: 0.3478 - val_loss: 1.5349 - val_accuracy: 0.5417 - val_mean_squared_error: 0.3717\n",
      "Epoch 4/15\n",
      "64/64 [==============================] - 24s 374ms/step - loss: 1.2641 - accuracy: 0.5900 - mean_squared_error: 0.3259 - val_loss: 1.4391 - val_accuracy: 0.5456 - val_mean_squared_error: 0.3577\n",
      "Epoch 5/15\n",
      "64/64 [==============================] - 24s 372ms/step - loss: 1.1660 - accuracy: 0.5981 - mean_squared_error: 0.3107 - val_loss: 1.3956 - val_accuracy: 0.5515 - val_mean_squared_error: 0.3524\n",
      "Epoch 6/15\n",
      "64/64 [==============================] - 24s 370ms/step - loss: 1.0890 - accuracy: 0.6047 - mean_squared_error: 0.2991 - val_loss: 1.3152 - val_accuracy: 0.5702 - val_mean_squared_error: 0.3394\n",
      "Epoch 7/15\n",
      "64/64 [==============================] - 24s 376ms/step - loss: 1.0230 - accuracy: 0.6081 - mean_squared_error: 0.2876 - val_loss: 1.2675 - val_accuracy: 0.5741 - val_mean_squared_error: 0.3311\n",
      "Epoch 8/15\n",
      "64/64 [==============================] - 24s 370ms/step - loss: 0.9666 - accuracy: 0.6280 - mean_squared_error: 0.2760 - val_loss: 1.2395 - val_accuracy: 0.5800 - val_mean_squared_error: 0.3277\n",
      "Epoch 9/15\n",
      "64/64 [==============================] - 23s 366ms/step - loss: 0.9179 - accuracy: 0.6419 - mean_squared_error: 0.2666 - val_loss: 1.2358 - val_accuracy: 0.5741 - val_mean_squared_error: 0.3289\n",
      "Epoch 10/15\n",
      "64/64 [==============================] - 24s 370ms/step - loss: 0.8870 - accuracy: 0.6493 - mean_squared_error: 0.2589 - val_loss: 1.2008 - val_accuracy: 0.5829 - val_mean_squared_error: 0.3182\n",
      "Epoch 11/15\n",
      "64/64 [==============================] - 23s 366ms/step - loss: 0.8388 - accuracy: 0.6610 - mean_squared_error: 0.2493 - val_loss: 1.1687 - val_accuracy: 0.5967 - val_mean_squared_error: 0.3134\n",
      "Epoch 12/15\n",
      "64/64 [==============================] - 24s 371ms/step - loss: 0.8029 - accuracy: 0.6640 - mean_squared_error: 0.2420 - val_loss: 1.1528 - val_accuracy: 0.6006 - val_mean_squared_error: 0.3109\n",
      "Epoch 13/15\n",
      "64/64 [==============================] - 24s 371ms/step - loss: 0.7791 - accuracy: 0.6747 - mean_squared_error: 0.2364 - val_loss: 1.1532 - val_accuracy: 0.5810 - val_mean_squared_error: 0.3132\n",
      "Epoch 14/15\n",
      "64/64 [==============================] - 24s 381ms/step - loss: 0.7428 - accuracy: 0.6855 - mean_squared_error: 0.2267 - val_loss: 1.1363 - val_accuracy: 0.5898 - val_mean_squared_error: 0.3105\n",
      "Epoch 15/15\n",
      "64/64 [==============================] - 23s 367ms/step - loss: 0.7180 - accuracy: 0.6939 - mean_squared_error: 0.2202 - val_loss: 1.1301 - val_accuracy: 0.5829 - val_mean_squared_error: 0.3099\n"
     ]
    }
   ],
   "source": [
    "print('# Fit model on training data')\n",
    "\n",
    "history = conv_model.fit(X_train, \n",
    "                    y_train, \n",
    "                    batch_size=64, \n",
    "                    shuffle = True,\n",
    "                    epochs=15,\n",
    "                    # We pass it validation data to\n",
    "                    # monitor loss and metrics\n",
    "                    # at the end of each epoch\n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigger Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_layer_size = 256\n",
    "img_size = IMG_SIZE\n",
    "\n",
    "conv_inputs = keras.Input(shape=(img_size[1], img_size[0],3), name='ani_image')\n",
    "conv_layer = layers.Conv2D(128, kernel_size=3, activation='relu')(conv_inputs)\n",
    "conv_layer = layers.MaxPool2D(pool_size=(2,2))(conv_layer)\n",
    "\n",
    "conv_layer = layers.Conv2D(128, kernel_size=3, activation='relu')(conv_layer)\n",
    "conv_layer = layers.MaxPool2D(pool_size=(2,2))(conv_layer)\n",
    "\n",
    "conv_x = layers.Flatten(name = 'flattened_features')(conv_layer) #turn image to vector.\n",
    "\n",
    "conv_x = layers.Dense(fc_layer_size, activation='relu', name='first_layer')(conv_x)\n",
    "conv_x = layers.Dense(fc_layer_size, activation='relu', name='second_layer')(conv_x)\n",
    "conv_outputs = layers.Dense(1, activation='sigmoid', name='class')(conv_x)\n",
    "\n",
    "huge_conv_model = keras.Model(inputs=conv_inputs, outputs=conv_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "customAdam = keras.optimizers.Adam(lr=1e-6)\n",
    "huge_conv_model.compile(optimizer=customAdam,  # Optimizer\n",
    "              # Loss function to minimize\n",
    "              loss=\"binary_crossentropy\",\n",
    "              # List of metrics to monitor\n",
    "              metrics=[\"binary_crossentropy\",\"mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Fit model on training data\n",
      "Epoch 1/5\n",
      "64/64 [==============================] - 84s 1s/step - loss: 1.6947 - binary_crossentropy: 1.6947 - mean_squared_error: 0.3899 - val_loss: 1.5061 - val_binary_crossentropy: 1.5061 - val_mean_squared_error: 0.3801\n",
      "Epoch 2/5\n",
      "64/64 [==============================] - 85s 1s/step - loss: 1.1473 - binary_crossentropy: 1.1473 - mean_squared_error: 0.3209 - val_loss: 1.2750 - val_binary_crossentropy: 1.2750 - val_mean_squared_error: 0.3484\n",
      "Epoch 3/5\n",
      "64/64 [==============================] - 85s 1s/step - loss: 0.9690 - binary_crossentropy: 0.9690 - mean_squared_error: 0.2891 - val_loss: 1.1285 - val_binary_crossentropy: 1.1285 - val_mean_squared_error: 0.3276\n",
      "Epoch 4/5\n",
      "64/64 [==============================] - 84s 1s/step - loss: 0.8789 - binary_crossentropy: 0.8789 - mean_squared_error: 0.2712 - val_loss: 1.0607 - val_binary_crossentropy: 1.0607 - val_mean_squared_error: 0.3126\n",
      "Epoch 5/5\n",
      "64/64 [==============================] - 85s 1s/step - loss: 0.8113 - binary_crossentropy: 0.8113 - mean_squared_error: 0.2553 - val_loss: 0.9996 - val_binary_crossentropy: 0.9996 - val_mean_squared_error: 0.3029\n"
     ]
    }
   ],
   "source": [
    "print('# Fit model on training data')\n",
    "\n",
    "history = huge_conv_model.fit(X_train, \n",
    "                    y_train, #we pass it th labels\n",
    "                    #If the model is taking forever to train, make this bigger\n",
    "                    #If it is taking forever to load for the first epoch, make this smaller\n",
    "                    batch_size=64, \n",
    "                    shuffle = True,\n",
    "                    epochs=5,\n",
    "                    # We pass it validation data to\n",
    "                    # monitor loss and metrics\n",
    "                    # at the end of each epoch\n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de Jason Brownlee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_layer_size = 256\n",
    "img_size = IMG_SIZE\n",
    "\n",
    "conv_inputs = keras.Input(shape=(img_size[1], img_size[0],3), name='ani_image')\n",
    "\n",
    "conv_layer = layers.Conv2D(64, kernel_size=3, activation='relu',\n",
    "                           kernel_initializer='he_uniform')(conv_inputs)\n",
    "conv_layer = layers.MaxPool2D(pool_size=(2,2))(conv_layer)\n",
    "\n",
    "conv_layer = layers.Dropout(0.2)(conv_layer)\n",
    "conv_layer = layers.Conv2D(64, kernel_size=3, activation='relu',\n",
    "                           kernel_initializer='he_uniform')(conv_layer)\n",
    "conv_layer = layers.MaxPool2D(pool_size=(2,2))(conv_layer)\n",
    "\n",
    "conv_layer = layers.Dropout(0.2)(conv_layer)\n",
    "conv_layer = layers.Conv2D(64, kernel_size=3, activation='relu',\n",
    "                           kernel_initializer='he_uniform')(conv_layer)\n",
    "conv_layer = layers.MaxPool2D(pool_size=(2,2))(conv_layer)\n",
    "\n",
    "conv_layer = layers.Dropout(0.2)(conv_layer)\n",
    "conv_x = layers.Flatten(name = 'flattened_features')(conv_layer) #turn image to vector.\n",
    "\n",
    "conv_x = layers.Dense(fc_layer_size, activation='relu', name='first_layer',\n",
    "                      kernel_initializer='he_uniform')(conv_x)\n",
    "conv_x = layers.Dropout(0.5)(conv_x)\n",
    "conv_x = layers.Dense(fc_layer_size, activation='relu', name='second_layer')(conv_x)\n",
    "conv_outputs = layers.Dense(1, activation='sigmoid', name='class')(conv_x)\n",
    "\n",
    "Brownlee_model = keras.Model(inputs=conv_inputs, outputs=conv_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "customAdam = keras.optimizers.Adam(lr=1e-6)\n",
    "Brownlee_model.compile(optimizer=customAdam,  # Optimizer\n",
    "              # Loss function to minimize\n",
    "              loss=\"binary_crossentropy\",\n",
    "              # List of metrics to monitor\n",
    "              metrics=[\"binary_crossentropy\",\"mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Fit model on training data\n",
      "Epoch 1/5\n",
      "64/64 [==============================] - 40s 617ms/step - loss: 148.5111 - binary_crossentropy: 148.5111 - mean_squared_error: 0.4880 - val_loss: 32.5123 - val_binary_crossentropy: 32.5123 - val_mean_squared_error: 0.4938\n",
      "Epoch 2/5\n",
      "64/64 [==============================] - 41s 643ms/step - loss: 128.4026 - binary_crossentropy: 128.4026 - mean_squared_error: 0.5074 - val_loss: 29.5024 - val_binary_crossentropy: 29.5024 - val_mean_squared_error: 0.4945\n",
      "Epoch 3/5\n",
      "64/64 [==============================] - 40s 632ms/step - loss: 120.4583 - binary_crossentropy: 120.4583 - mean_squared_error: 0.4959 - val_loss: 28.5973 - val_binary_crossentropy: 28.5973 - val_mean_squared_error: 0.4930\n",
      "Epoch 4/5\n",
      "64/64 [==============================] - 40s 629ms/step - loss: 112.6544 - binary_crossentropy: 112.6544 - mean_squared_error: 0.4951 - val_loss: 26.3280 - val_binary_crossentropy: 26.3280 - val_mean_squared_error: 0.4864\n",
      "Epoch 5/5\n",
      "64/64 [==============================] - 41s 639ms/step - loss: 106.4453 - binary_crossentropy: 106.4453 - mean_squared_error: 0.5057 - val_loss: 25.7587 - val_binary_crossentropy: 25.7587 - val_mean_squared_error: 0.4885\n"
     ]
    }
   ],
   "source": [
    "print('# Fit model on training data')\n",
    "\n",
    "history = Brownlee_model.fit(X_train, \n",
    "                    y_train, #we pass it th labels\n",
    "                    #If the model is taking forever to train, make this bigger\n",
    "                    #If it is taking forever to load for the first epoch, make this smaller\n",
    "                    batch_size=64, \n",
    "                    shuffle = True,\n",
    "                    epochs=5,                             \n",
    "                    # We pass it validation data to\n",
    "                    # monitor loss and metrics\n",
    "                    # at the end of each epoch\n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "64/64 [==============================] - 121s 2s/step - loss: 5.4601 - binary_crossentropy: 5.4601 - mean_squared_error: 0.3847 - val_loss: 5.3756 - val_binary_crossentropy: 5.3756 - val_mean_squared_error: 0.3758\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 121s 2s/step - loss: 4.8114 - binary_crossentropy: 4.8114 - mean_squared_error: 0.3669 - val_loss: 4.7586 - val_binary_crossentropy: 4.7586 - val_mean_squared_error: 0.3695\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 122s 2s/step - loss: 4.3781 - binary_crossentropy: 4.3781 - mean_squared_error: 0.3536 - val_loss: 4.3236 - val_binary_crossentropy: 4.3236 - val_mean_squared_error: 0.3608\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 120s 2s/step - loss: 4.0675 - binary_crossentropy: 4.0675 - mean_squared_error: 0.3430 - val_loss: 4.0012 - val_binary_crossentropy: 4.0012 - val_mean_squared_error: 0.3480\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 122s 2s/step - loss: 3.8242 - binary_crossentropy: 3.8242 - mean_squared_error: 0.3339 - val_loss: 3.7482 - val_binary_crossentropy: 3.7482 - val_mean_squared_error: 0.3338\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 124s 2s/step - loss: 3.6198 - binary_crossentropy: 3.6198 - mean_squared_error: 0.3238 - val_loss: 3.5484 - val_binary_crossentropy: 3.5484 - val_mean_squared_error: 0.3225\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 124s 2s/step - loss: 3.4456 - binary_crossentropy: 3.4456 - mean_squared_error: 0.3147 - val_loss: 3.3830 - val_binary_crossentropy: 3.3830 - val_mean_squared_error: 0.3138\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 128s 2s/step - loss: 3.2938 - binary_crossentropy: 3.2938 - mean_squared_error: 0.3055 - val_loss: 3.2374 - val_binary_crossentropy: 3.2374 - val_mean_squared_error: 0.3045\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 122s 2s/step - loss: 3.1573 - binary_crossentropy: 3.1573 - mean_squared_error: 0.2972 - val_loss: 3.1119 - val_binary_crossentropy: 3.1119 - val_mean_squared_error: 0.2961\n",
      "Epoch 10/10\n",
      "31/64 [=============>................] - ETA: 49s - loss: 3.2564 - binary_crossentropy: 3.2564 - mean_squared_error: 0.2966"
     ]
    }
   ],
   "source": [
    "# define cnn model\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "\n",
    "img_size = IMG_SIZE\n",
    "\n",
    "model_VGG16 = VGG16(include_top=False, input_shape=(img_size[1], img_size[0],3))\n",
    "for layer in model_VGG16.layers:\n",
    "   layer.trainable = False\n",
    "\n",
    "flat1  = Flatten()(model_VGG16.layers[-1].output)\n",
    "class1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
    "output = Dense(1, activation='sigmoid')(class1)\n",
    "\n",
    "model_VGG16 = Model(inputs=model_VGG16.inputs, outputs=output)\n",
    "\n",
    "customAdam = keras.optimizers.Adam(lr=1e-6)\n",
    "model_VGG16.compile(optimizer=customAdam,  # Optimizer\n",
    "              # Loss function to minimize\n",
    "              loss=\"binary_crossentropy\",\n",
    "              # List of metrics to monitor\n",
    "              metrics=[\"binary_crossentropy\",\"mean_squared_error\"])\n",
    "\n",
    "\n",
    "history = model_VGG16.fit(X_train, \n",
    "                    y_train, #we pass it th labels\n",
    "                    #If the model is taking forever to train, make this bigger\n",
    "                    #If it is taking forever to load for the first epoch, make this smaller\n",
    "                    batch_size = 64, \n",
    "                    shuffle = True,\n",
    "                    epochs=10,                             \n",
    "                    # We pass it validation data to\n",
    "                    # monitor loss and metrics\n",
    "                    # at the end of each epoch\n",
    "                    validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
